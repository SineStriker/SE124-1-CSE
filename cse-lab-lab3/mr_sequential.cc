//
// A simple sequential MapReduce for WordCount
//

#include <algorithm>
#include <fstream>
#include <iostream>
#include <sstream>
#include <string>
#include <vector>

using namespace std;

typedef struct {
    string key;
    string val;
} KeyVal;

//
// The map function is called once for each file of input. The first
// argument is the name of the input file, and the second is the
// file's complete contents. You should ignore the input file name,
// and look only at the contents argument. The return value is a slice
// of key/value pairs.
//

char toLower(char c) {
    if (c >= 'A' && c <= 'Z') {
        return c + ('a' - 'A');
    }
    return c;
}

bool compare(const string &s1, const string &s2) {
    size_t m = min(s1.size(), s2.size());
    for (size_t i = 0; i < m; ++i) {
        char c1 = toLower(s1.at(i));
        char c2 = toLower(s2.at(i));
        if (c1 != c2) {
            return c1 < c2;
        }
    }
    if (s1.size() != s2.size()) {
        return s1.size() < s2.size();
    }
    return s1 < s2;
}

vector<KeyVal> Map(const string &filename, const string &content) {
    // Your code goes here
    // Hints: split contents into an array of words.

    size_t cur = 0, i;
    vector<KeyVal> res;
    while (cur <= content.size()) {
        for (i = cur; i < content.size(); ++i) {
            char ch = content.at(i);
            if (!((ch >= 'a' && ch <= 'z') || (ch >= 'A' && ch <= 'Z'))) {
                break;
            }
        }
        string str = content.substr(cur, i - cur);
        if (!str.empty()) {
            KeyVal kv;
            kv.key = content.substr(cur, i - cur);
            kv.val = "1";
            res.push_back(kv);
        }

        cur = i + 1;
    }

    return res;
}

//
// The reduce function is called once for each key generated by the
// map tasks, with a list of all the values created for that key by
// any map task.
//
string Reduce(const string &key, const vector<string> &values) {
    // Your code goes here
    // Hints: return the number of occurrences of the word.

    int total = 0;
    for (size_t i = 0; i < values.size(); ++i) {
        stringstream ss;
        int cur = 0;
        ss << values.at(i);
        ss >> cur;
        // if (ss.good()) {
        total += cur;
        // }
    }

    string res;
    stringstream ss;
    ss << total;
    ss >> res;

    return res;
}

int main(int argc, char **argv) {
    if (argc < 2) {
        cout << "Usage: mrsequential inputfiles...\n";
        exit(1);
    }

    vector<KeyVal> intermediate;

    //
    // read each input file,
    // pass it to Map,
    // accumulate the intermediate Map output.
    //

    for (int i = 1; i < argc; ++i) {

        string filename = argv[i];
        string content;

        // Read the whole file into the buffer.
        getline(ifstream(filename), content, '\0');

        vector<KeyVal> KVA = Map(filename, content);

        intermediate.insert(intermediate.end(), KVA.begin(), KVA.end());
    }

    //
    // a big difference from real MapReduce is that all the
    // intermediate data is in one place, intermediate[],
    // rather than being partitioned into NxM buckets.
    //

    sort(intermediate.begin(), intermediate.end(), [](KeyVal const &a, KeyVal const &b) { return compare(a.key, b.key); });

    //
    // call Reduce on each distinct key in intermediate[],
    // and print the result to mr-out-0.
    //

    for (unsigned int i = 0; i < intermediate.size();) {
        unsigned int j = i + 1;
        for (; j < intermediate.size() && intermediate[j].key == intermediate[i].key;)
            j++;

        vector<string> values;
        for (unsigned int k = i; k < j; k++) {
            values.push_back(intermediate[k].val);
        }

        string output = Reduce(intermediate[i].key, values);
        printf("%s %s\n", intermediate[i].key.data(), output.data());

        i = j;
    }
    return 0;
}
